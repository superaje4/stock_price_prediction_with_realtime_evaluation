{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b85c4539-7577-4af3-93aa-80075ee230ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting selenium\n",
      "  Using cached selenium-4.17.2-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: urllib3<3,>=1.26 in c:\\users\\asus\\anaconda3\\envs\\scrap\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (2.1.0)\n",
      "Collecting trio~=0.17 (from selenium)\n",
      "  Using cached trio-0.24.0-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting trio-websocket~=0.9 (from selenium)\n",
      "  Using cached trio_websocket-0.11.1-py3-none-any.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\asus\\anaconda3\\envs\\scrap\\lib\\site-packages (from selenium) (2024.2.2)\n",
      "Requirement already satisfied: typing_extensions>=4.9.0 in c:\\users\\asus\\anaconda3\\envs\\scrap\\lib\\site-packages (from selenium) (4.9.0)\n",
      "Requirement already satisfied: attrs>=20.1.0 in c:\\users\\asus\\anaconda3\\envs\\scrap\\lib\\site-packages (from trio~=0.17->selenium) (23.1.0)\n",
      "Collecting sortedcontainers (from trio~=0.17->selenium)\n",
      "  Using cached sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
      "Requirement already satisfied: idna in c:\\users\\asus\\anaconda3\\envs\\scrap\\lib\\site-packages (from trio~=0.17->selenium) (3.4)\n",
      "Collecting outcome (from trio~=0.17->selenium)\n",
      "  Using cached outcome-1.3.0.post0-py2.py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in c:\\users\\asus\\anaconda3\\envs\\scrap\\lib\\site-packages (from trio~=0.17->selenium) (1.3.0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\asus\\anaconda3\\envs\\scrap\\lib\\site-packages (from trio~=0.17->selenium) (1.16.0)\n",
      "Requirement already satisfied: exceptiongroup in c:\\users\\asus\\appdata\\roaming\\python\\python310\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Collecting wsproto>=0.14 (from trio-websocket~=0.9->selenium)\n",
      "  Using cached wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
      "Collecting pysocks!=1.5.7,<2.0,>=1.5.6 (from urllib3[socks]<3,>=1.26->selenium)\n",
      "  Using cached PySocks-1.7.1-py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: pycparser in c:\\users\\asus\\anaconda3\\envs\\scrap\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Collecting h11<1,>=0.9.0 (from wsproto>=0.14->trio-websocket~=0.9->selenium)\n",
      "  Using cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Using cached selenium-4.17.2-py3-none-any.whl (9.9 MB)\n",
      "Using cached trio-0.24.0-py3-none-any.whl (460 kB)\n",
      "Using cached trio_websocket-0.11.1-py3-none-any.whl (17 kB)\n",
      "Using cached outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n",
      "Installing collected packages: sortedcontainers, pysocks, outcome, h11, wsproto, trio, trio-websocket, selenium\n",
      "Successfully installed h11-0.14.0 outcome-1.3.0.post0 pysocks-1.7.1 selenium-4.17.2 sortedcontainers-2.4.0 trio-0.24.0 trio-websocket-0.11.1 wsproto-1.2.0\n",
      "Collecting undetected-chromedriver\n",
      "  Downloading undetected-chromedriver-3.5.4.tar.gz (65 kB)\n",
      "     ---------------------------------------- 0.0/65.4 kB ? eta -:--:--\n",
      "     ------ --------------------------------- 10.2/65.4 kB ? eta -:--:--\n",
      "     ----------------------------------- -- 61.4/65.4 kB 825.8 kB/s eta 0:00:01\n",
      "     -------------------------------------- 65.4/65.4 kB 889.5 kB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: selenium>=4.9.0 in c:\\users\\asus\\anaconda3\\envs\\scrap\\lib\\site-packages (from undetected-chromedriver) (4.17.2)\n",
      "Requirement already satisfied: requests in c:\\users\\asus\\anaconda3\\envs\\scrap\\lib\\site-packages (from undetected-chromedriver) (2.31.0)\n",
      "Collecting websockets (from undetected-chromedriver)\n",
      "  Downloading websockets-12.0-cp310-cp310-win_amd64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: urllib3<3,>=1.26 in c:\\users\\asus\\anaconda3\\envs\\scrap\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium>=4.9.0->undetected-chromedriver) (2.1.0)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\asus\\anaconda3\\envs\\scrap\\lib\\site-packages (from selenium>=4.9.0->undetected-chromedriver) (0.24.0)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\asus\\anaconda3\\envs\\scrap\\lib\\site-packages (from selenium>=4.9.0->undetected-chromedriver) (0.11.1)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\asus\\anaconda3\\envs\\scrap\\lib\\site-packages (from selenium>=4.9.0->undetected-chromedriver) (2024.2.2)\n",
      "Requirement already satisfied: typing_extensions>=4.9.0 in c:\\users\\asus\\anaconda3\\envs\\scrap\\lib\\site-packages (from selenium>=4.9.0->undetected-chromedriver) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\asus\\anaconda3\\envs\\scrap\\lib\\site-packages (from requests->undetected-chromedriver) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\asus\\anaconda3\\envs\\scrap\\lib\\site-packages (from requests->undetected-chromedriver) (3.4)\n",
      "Requirement already satisfied: attrs>=20.1.0 in c:\\users\\asus\\anaconda3\\envs\\scrap\\lib\\site-packages (from trio~=0.17->selenium>=4.9.0->undetected-chromedriver) (23.1.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\asus\\anaconda3\\envs\\scrap\\lib\\site-packages (from trio~=0.17->selenium>=4.9.0->undetected-chromedriver) (2.4.0)\n",
      "Requirement already satisfied: outcome in c:\\users\\asus\\anaconda3\\envs\\scrap\\lib\\site-packages (from trio~=0.17->selenium>=4.9.0->undetected-chromedriver) (1.3.0.post0)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in c:\\users\\asus\\anaconda3\\envs\\scrap\\lib\\site-packages (from trio~=0.17->selenium>=4.9.0->undetected-chromedriver) (1.3.0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\asus\\anaconda3\\envs\\scrap\\lib\\site-packages (from trio~=0.17->selenium>=4.9.0->undetected-chromedriver) (1.16.0)\n",
      "Requirement already satisfied: exceptiongroup in c:\\users\\asus\\appdata\\roaming\\python\\python310\\site-packages (from trio~=0.17->selenium>=4.9.0->undetected-chromedriver) (1.2.0)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\asus\\anaconda3\\envs\\scrap\\lib\\site-packages (from trio-websocket~=0.9->selenium>=4.9.0->undetected-chromedriver) (1.2.0)\n",
      "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\asus\\anaconda3\\envs\\scrap\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium>=4.9.0->undetected-chromedriver) (1.7.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\asus\\anaconda3\\envs\\scrap\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium>=4.9.0->undetected-chromedriver) (2.21)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\asus\\anaconda3\\envs\\scrap\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium>=4.9.0->undetected-chromedriver) (0.14.0)\n",
      "Downloading websockets-12.0-cp310-cp310-win_amd64.whl (124 kB)\n",
      "   ---------------------------------------- 0.0/125.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 125.0/125.0 kB 2.4 MB/s eta 0:00:00\n",
      "Building wheels for collected packages: undetected-chromedriver\n",
      "  Building wheel for undetected-chromedriver (setup.py): started\n",
      "  Building wheel for undetected-chromedriver (setup.py): finished with status 'done'\n",
      "  Created wheel for undetected-chromedriver: filename=undetected_chromedriver-3.5.4-py3-none-any.whl size=47139 sha256=f0f974503e5fd3301019f9388a46c4594cff80abc5a75d834d5f6368ffdeaa19\n",
      "  Stored in directory: c:\\users\\asus\\appdata\\local\\pip\\cache\\wheels\\0c\\a6\\72\\5c948853baf75d52f1da173bd8fc9d7ad7615608e0ffaead6d\n",
      "Successfully built undetected-chromedriver\n",
      "Installing collected packages: websockets, undetected-chromedriver\n",
      "Successfully installed undetected-chromedriver-3.5.4 websockets-12.0\n",
      "Requirement already satisfied: requests in c:\\users\\asus\\anaconda3\\envs\\scrap\\lib\\site-packages (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\asus\\anaconda3\\envs\\scrap\\lib\\site-packages (from requests) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\asus\\anaconda3\\envs\\scrap\\lib\\site-packages (from requests) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\asus\\anaconda3\\envs\\scrap\\lib\\site-packages (from requests) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\asus\\anaconda3\\envs\\scrap\\lib\\site-packages (from requests) (2024.2.2)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\asus\\anaconda3\\envs\\scrap\\lib\\site-packages (4.12.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\asus\\anaconda3\\envs\\scrap\\lib\\site-packages (from beautifulsoup4) (2.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium\n",
    "!pip install undetected-chromedriver\n",
    "!pip install requests\n",
    "!pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d9b0645-c2ed-49eb-899b-8ecaf6698326",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from selenium.webdriver.common.keys import Keys#untuk tekan tekan\n",
    "from selenium.webdriver.common.by import By#untuk nyari element\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import undetected_chromedriver\n",
    "import selenium\n",
    "import requests\n",
    "import bs4\n",
    "from datetime import date,timedelta\n",
    "import re\n",
    "import holidays"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e77db71-5464-41b1-bc35-af6f01de0c76",
   "metadata": {},
   "source": [
    "## Buka site BEI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72d8e8fb-6936-44e6-a511-2d406c675ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=selenium.webdriver.Chrome()\n",
    "url=\"https://www.idx.co.id/id/data-pasar/ringkasan-perdagangan/ringkasan-saham/\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "498c4be7-a01a-4e2d-88c2-46c7d7bb17dc",
   "metadata": {},
   "source": [
    "### filter tanggal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "b4216c97-7fb5-4e46-ab7e-9dfca1682e12",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-01-02\n",
      "2020-01-03\n",
      "2020-01-06\n",
      "2020-01-07\n",
      "2020-01-08\n"
     ]
    }
   ],
   "source": [
    "from datetime import date\n",
    "import datetime as dt\n",
    "import holidays\n",
    "\n",
    "import pandas as pd\n",
    "# Membuat rentang tanggal\n",
    "start_date = '2020-01-01'\n",
    "\n",
    "now = datetime.now()\n",
    "one_day_before = now - timedelta(days=1)\n",
    "end_date = one_day_before.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# hanya mengganbil tanggal kerja dan bukan sabtu dan minggu\n",
    "def filter_tanggal(date):\n",
    "    date=[i for i in date if i not in holidays.IDN()]\n",
    "    date=[i for i in date if i.dayofweek not in [5,6]]\n",
    "    return date\n",
    "    \n",
    "dates = pd.date_range(start=start_date, end=end_date)\n",
    "dates=filter_tanggal(dates)\n",
    "\n",
    "# Memformat tanggal ke format DD-MM-YYYY\n",
    "formatted_dates = [date.strftime('%Y-%m-%d') for date in dates]\n",
    "\n",
    "\n",
    "# Menampilkan beberapa tanggal terformat\n",
    "for date in formatted_dates[:5]:\n",
    "    print(date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "6e5b7bca-7585-4852-bf2e-07ac4682be68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2020-01-02', '2020-01-03', '2020-01-06', '2020-01-07', '2020-01-08']"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formatted_dates[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "c871c4b7-9a7b-4c40-9495-fa72aa5adbfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tanggal=driver.find_element(By.CSS_SELECTOR,\"#app > div.sticky-footer-container-item.--pushed > main > div > div.mb-24.filter > div.filter-items > div.full-responsive.filter-center > div.mx-datepicker > div > input\")\n",
    "tanggal.click()\n",
    "tanggal.clear()\n",
    "tanggal.send_keys(\"2020-01-02\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "c7dbee99-c660-4f48-a580-aef10d212a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "nama_perusahaan=driver.find_element(By.CSS_SELECTOR,\"#FilterSearch\")\n",
    "nama_perusahaan.send_keys(\"BMRI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "65a2696a-e194-4c49-b90b-17ba54886d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup=bs4.BeautifulSoup(driver.page_source,\"html.parser\")\n",
    "postingan=soup.find_all('td',class_=\"vgt-right-align\")\n",
    "harga=postingan[2].text.strip()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6860bc9-303f-4e10-b8b9-b0a1c038609f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ambil_data(perusahaan)\n",
    "for i in formatted_dates[2:10]:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "8d65b68c-f31d-4a53-befa-306fea1a5e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_hari,list_harga= list(),list()\n",
    "for i in formatted_dates[2:10]:\n",
    "    tanggal=driver.find_element(By.CSS_SELECTOR,\"#app > div.sticky-footer-container-item.--pushed > main > div > div.mb-24.filter > div.filter-items > div.full-responsive.filter-center > div.mx-datepicker > div > input\")\n",
    "    tanggal.click()\n",
    "    tanggal.clear()\n",
    "    tanggal.send_keys(i)\n",
    "    nama_perusahaan.click()\n",
    "    WebDriverWait(driver, 10).until(\n",
    "        EC.presence_of_element_located((By.CSS_SELECTOR, \"#vgt-table > tbody > tr > td:nth-child(2)\")))\n",
    "    \n",
    "    soup=bs4.BeautifulSoup(driver.page_source,\"html.parser\")\n",
    "    postingan=soup.find_all('td',class_=\"vgt-right-align\")\n",
    "    if postingan:\n",
    "        harga=postingan[2].text.strip()\n",
    "    else:\n",
    "        harga=\"unk\"\n",
    "    list_hari.append(i)\n",
    "    list_harga.append(harga)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "c0256eb0-060d-45a6-9645-6e66071519d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tanggal</th>\n",
       "      <th>harga</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-06</td>\n",
       "      <td>7.600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-07</td>\n",
       "      <td>7.600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-08</td>\n",
       "      <td>7.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-09</td>\n",
       "      <td>7.700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-10</td>\n",
       "      <td>7.725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2020-01-13</td>\n",
       "      <td>7.725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2020-01-14</td>\n",
       "      <td>7.750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2020-01-15</td>\n",
       "      <td>7.650</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      tanggal  harga\n",
       "0  2020-01-06  7.600\n",
       "1  2020-01-07  7.600\n",
       "2  2020-01-08  7.500\n",
       "3  2020-01-09  7.700\n",
       "4  2020-01-10  7.725\n",
       "5  2020-01-13  7.725\n",
       "6  2020-01-14  7.750\n",
       "7  2020-01-15  7.650"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({\"tanggal\":list_hari,\"harga\":list_harga})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78239a95-6ca2-4d65-aac3-46bf28f81bdd",
   "metadata": {},
   "source": [
    "## Buat fungsi sempurna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ddc12e4a-d73f-4a69-b008-b38bf3170652",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "import datetime as dt\n",
    "import holidays\n",
    "import pandas as pd\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0794d178-b4f6-47fb-b5ee-412f05f0b9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ambil_data_perusahaan(perusahaan):\n",
    "    \n",
    "    # Membuat rentang tanggal\n",
    "    from datetime import date\n",
    "    import datetime as dt\n",
    "    import holidays\n",
    "    import pandas as pd\n",
    "    \n",
    "    start_date = '2020-01-01'\n",
    "    now = datetime.now()\n",
    "    one_day_before = now - timedelta(days=1)\n",
    "    end_date = one_day_before.strftime(\"%Y-%m-%d\")\n",
    "    \n",
    "    # hanya mengganbil tanggal kerja dan bukan sabtu dan minggu\n",
    "    def filter_tanggal(date):\n",
    "        date=[i for i in date if i not in holidays.IDN()]\n",
    "        date=[i for i in date if i.dayofweek not in [5,6]]\n",
    "        return date\n",
    "        \n",
    "    dates = pd.date_range(start=start_date, end=end_date)\n",
    "    dates=filter_tanggal(dates)\n",
    "    \n",
    "    # Memformat tanggal ke format DD-MM-YYYY\n",
    "    formatted_dates = [date.strftime('%Y-%m-%d') for date in dates]\n",
    "    \n",
    "    #siapkan driver\n",
    "    driver=selenium.webdriver.Chrome()\n",
    "    url=\"https://www.idx.co.id/id/data-pasar/ringkasan-perdagangan/ringkasan-saham/\"\n",
    "    driver.get(url)\n",
    "    time.sleep(2)\n",
    "    #tulis nama perusahaan\n",
    "    nama_perusahaan=driver.find_element(By.CSS_SELECTOR,\"#FilterSearch\")\n",
    "    nama_perusahaan.send_keys(perusahaan)\n",
    "\n",
    "    #buat tabel data\n",
    "    list_hari,list_harga= list(),list()\n",
    "    for i in formatted_dates:\n",
    "        tanggal=driver.find_element(By.CSS_SELECTOR,\"#app > div.sticky-footer-container-item.--pushed > main > div > div.mb-24.filter > div.filter-items > div.full-responsive.filter-center > div.mx-datepicker > div > input\")\n",
    "        tanggal.click()\n",
    "        tanggal.clear()\n",
    "        tanggal.send_keys(i)\n",
    "        nama_perusahaan.click()\n",
    "        try:\n",
    "            WebDriverWait(driver, 8).until(\n",
    "                EC.presence_of_element_located((By.CSS_SELECTOR, \"#vgt-table > tbody > tr > td:nth-child(2)\")))\n",
    "            \n",
    "            soup=bs4.BeautifulSoup(driver.page_source,\"html.parser\")\n",
    "            postingan=soup.find_all('td',class_=\"vgt-right-align\")\n",
    "            harga=postingan[2].text.strip()\n",
    "        except:\n",
    "            harga=\"unk\"\n",
    "            \n",
    "        list_hari.append(i)\n",
    "        list_harga.append(harga)\n",
    "\n",
    "    #hasilkan dataframe\n",
    "    df=pd.DataFrame({\"tanggal\":list_hari,\"harga\":list_harga})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7f812036-3e73-465d-8409-170f6dbbd94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_mandiri=ambil_data_perusahaan(\"BMRI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "17926918-065b-4576-8928-bbcf09119475",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tanggal</th>\n",
       "      <th>harga</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>7.750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>7.725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-06</td>\n",
       "      <td>7.600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-07</td>\n",
       "      <td>7.600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-08</td>\n",
       "      <td>7.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1030</th>\n",
       "      <td>2024-02-19</td>\n",
       "      <td>7.150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1031</th>\n",
       "      <td>2024-02-20</td>\n",
       "      <td>7.150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1032</th>\n",
       "      <td>2024-02-21</td>\n",
       "      <td>7.250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1033</th>\n",
       "      <td>2024-02-22</td>\n",
       "      <td>7.100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1034</th>\n",
       "      <td>2024-02-23</td>\n",
       "      <td>7.050</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1035 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         tanggal  harga\n",
       "0     2020-01-02  7.750\n",
       "1     2020-01-03  7.725\n",
       "2     2020-01-06  7.600\n",
       "3     2020-01-07  7.600\n",
       "4     2020-01-08  7.500\n",
       "...          ...    ...\n",
       "1030  2024-02-19  7.150\n",
       "1031  2024-02-20  7.150\n",
       "1032  2024-02-21  7.250\n",
       "1033  2024-02-22  7.100\n",
       "1034  2024-02-23  7.050\n",
       "\n",
       "[1035 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_mandiri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2a0dfef0-517d-4c48-822a-2cf6a7bc4073",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_mandiri.to_csv(\"data_mandiri.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
